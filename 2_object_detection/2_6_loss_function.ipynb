{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2_6_loss_function.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1NvaXWMvtjgIOMaVI2vztIL8UqNT2M5_4","authorship_tag":"ABX9TyP7Uykdv9uci8LYLbLVrlp7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2cDb_VGJOVj3","executionInfo":{"status":"ok","timestamp":1658230360424,"user_tz":-540,"elapsed":9996,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"80711b7d-5773-4446-c323-2ac8bdf3f004"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/data_science_project/pytorch_tutorial/2_object_detection\n","!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9GJSa2NSOxZG","executionInfo":{"status":"ok","timestamp":1658230366589,"user_tz":-540,"elapsed":493,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"cd1e37cd-5403-4c78-ed05-03637fec98c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/data_science_project/pytorch_tutorial/2_object_detection\n","/content/drive/MyDrive/data_science_project/pytorch_tutorial/2_object_detection\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from utils.match import match"],"metadata":{"id":"ir1lRkbPO1oG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MultiBoxLoss(nn.Module):\n","    \"\"\"SSD의 손실함수 클래스\"\"\"\n","\n","    def __init__(self, jaccard_thresh=0.5, neg_pos=3, device='cpu'):\n","        super(MultiBoxLoss, self).__init__()\n","        self.jaccard_thresh = jaccard_thresh\n","        self.negpos_ratio = neg_pos\n","        self.device = device\n","\n","    def forward(self, predictions, targets):\n","        \"\"\"\n","        손실함수 계산\n","\n","        predictions : SSD net 훈련시의 출력 (tuple)\n","            (loc=torch.Size([num_batch, 8732, 4]), conf=torch.Size([num_batch, 8732, 21]), dbox_list=torch.Size [8732,4])\n","\n","        targets : [num_batch, num_objs, 5]\n","            5는 정답의 어노테이션 정보[xmin, ymin, xmax, ymax, label_ind]를 나타낸다\n","\n","        Returns\n","        -------\n","        loss_l : 텐서\n","            loc의 손실값\n","        loss_c : 텐서\n","            conf의 손실값\n","\n","        \"\"\"\n","\n","        # SSD 모델의 출력이 튜플로 되어 있으므로 개별적으로 해체\n","        loc_data, conf_data, dbox_list = predictions\n","\n","        # 요소 수 파악\n","        num_batch = loc_data.size(0)  # 미니배치 크기\n","        num_dbox = loc_data.size(1)  # DBox 수 = 8732\n","        num_classes = conf_data.size(2)  # 클래스 수 = 21\n","\n","        # 손실 계산에 사용할 것을 저장하는 변수를 작성\n","        # conf_t_label: 각 DBox에 가장 가까운 정답 BBox의 라벨을 저장\n","        # loc_t: 각 DBox에 가장 가까운 정답 BBox의 위치 정보를 저장\n","        conf_t_label = torch.LongTensor(num_batch, num_dbox).to(self.device)\n","        loc_t = torch.Tensor(num_batch, num_dbox, 4).to(self.device)\n","\n","        # loc_t와 conf_t_label에,\n","        # DBox와 정답 어노테이션 targets를 match 시킨 결과를 덮어쓰기\n","        for idx in range(num_batch):  # 미니배치 루프\n","            # 현재 미니 뱃지의 정답 어노테이션의 BBox와 라벨을 취득\n","            truths = targets[idx][:, :-1].to(self.device)  # BBox\n","            # 라벨 [물체1의 라벨, 물체2의 라벨, …]\n","            labels = targets[idx][:, -1].to(self.device)\n","\n","            # 디폴트 박스를 새로운 변수로 준비\n","            dbox = dbox_list.to(self.device)\n","\n","            # match 함수를 실행하여 loc_t와 conf_t_label의 내용을 갱신한다\n","            # (상세)\n","            # loc_t: 각 DBox에 가장 가까운 정답 BBox의 위치 정보가 덮어써진다\n","            # conf_t_label: 각 DBox에 가장 가까운 BBox의 라벨이 덮어써진다\n","            # 단, 가장 가까운 BBox와의 jaccard overlap이 0.5보다 작은 경우\n","            # 정답 BBox의 라벨 conf_t_label은 배경 클래스 0으로 한다\n","            variance = [0.1, 0.2]\n","            # 이 variance는 DBox에서 BBox로 보정 계산할 때 사용하는 식의 계수입니다\n","            match(self.jaccard_thresh, truths, dbox,\n","                  variance, labels, loc_t, conf_t_label, idx)\n","            \n","            # ----------\n","            # 위치의 손실: loss_l을 계산\n","            # Smooth L1 함수로 손실을 계산한다. 단, 물체를 발견한 DBox의 오프셋만 계산한다\n","            # ----------\n","            # 물체를 감지한 BBox를 꺼내는 마스크를 작성\n","            pos_mask = conf_t_label > 0  # torch.Size([num_batch, 8732]) # conf_t_label에는 DBox마다 jaccard 계수가 가장 큰 정답 박스의 레이블이 들어가있다.\n","\n","            # pos_mask를 loc_data 크기로 변형\n","            pos_idx = pos_mask.unsqueeze(pos_mask.dim()).expand_as(loc_data)\n","\n","            # Positive DBox의 loc_data와 지도 데이터 loc_t를 취득\n","            loc_p = loc_data[pos_idx].view(-1, 4)\n","            loc_t = loc_t[pos_idx].view(-1, 4)\n","\n","            # 물체를 발견한 Positive DBox의 오프셋 정보 loc_t의 손실(오차)을 계산\n","            loss_l = F.smooth_l1_loss(loc_p, loc_t, reduction='sum')\n","\n","            # ----------\n","            # 클래스 예측의 손실: loss_c를 계산\n","            # 교차 엔트로피 오차 함수로 손실을 계산한다. 단, 배경 클래스가 정답인 DBox가 압도적으로 많으므로,\n","            # Hard Negative Mining을 실시하여 물체 발견 DBox 및 배경 클래스 DBox의 비율이 1:3이 되도록 한다.\n","            # 배경 클래스 DBox로 예상한 것 중에서 손실이 적은 것은, 클래스 예측 손실에서 제외한다\n","            # ----------\n","            batch_conf = conf_data.view(-1, num_classes)\n","\n","            # 클래스 예측의 손실 함수를 계산(reduction = 'none'으로 하여, 합을 취하지 않고, 차원을 보존한다)\n","            loss_c = F.cross_entropy(\n","            batch_conf, conf_t_label.view(-1), reduction='none')\n","            # -----------------\n","            # 이제 Negative DBox 중에서 Hard Negative Mining으로 추출하는 것을 구하는 마스크를 작성합니다\n","            # -----------------\n","\n","            # 물체 발견한 Positive DBox의 손실을 0으로 한다\n","            # (주의)물체는 label이 1 이상으로 되어 있다. 라벨 0은 배경을 의미.\n","            num_pos = pos_mask.long().sum(1, keepdim=True)  # 미니배치별 물체 클래스 예측의 수\n","            loss_c = loss_c.view(num_batch, -1)  # torch.Size([num_batch, 8732])\n","            loss_c[pos_mask] = 0  # 물체를 발견한 DBox는 손실 0으로 한다(임시)\n","\n","            # Hard Negative Mining을 실시\n","            # 각 DBox 손실의 크기 loss_c의 순위 idx_rank을 구한다\n","            _, loss_idx = loss_c.sort(1, descending=True)\n","            _, idx_rank = loss_idx.sort(1)\n","\n","            # (주석)\n","            # 구현된 코드는 특수하며 직관적이지 않습니다.\n","            # 위 두 줄의 요점은 각 DBox에 대해, 손실 크기가 몇 번째인지의 정보를\n","            # 변수 idx_rank에 고속으로 취득하는 코드입니다.\n","            \n","            # DBox의 손실 값이 큰 쪽에서 내림차순으로 정렬하여, DBox의 내림차순의 index를 loss_idx에 저장한다.\n","            # 손실 크기 loss_c의 순위 idx_rank를 구한다.\n","            # 여기서 내림차순이 된 배열 index인 loss_idx를 0부터 8732까지 오름차순으로 다시 정렬하기 위해서는,\n","            # 몇 번째 loss_idx의 인덱스를 취할지를 나타내는 것이 idx_rank이다.\n","            # 예를 들면, idx_rank 요소의 0번째 = idx_rank[0]를 구하려면 loss_idx의 값이 0인 요소,\n","            # 즉 loss_idx[?]=0의, ?는 몇 번째를 구할 것인지가 된다. 여기서 ? = idx_rank[0] 이다.\n","            # 지금 loss_idx[?]=0의 0은, 원래 loss_cの의 요소 0번째라는 의미이다.\n","            # 즉 ?은 원래 loss_c의 요소 0번째는, 내림차순으로 정렬된 loss_idx의 몇 번째입니까?\n","            # 를 구하는 것이 되어, 결과적으로\n","            # ? = idx_rank[0] 은 loss_c의 요소 0번째가 내림차순으로 몇 번째인지 나타낸다.\n","\n","            # 배경 DBox의 수 num_neg를 구한다. HardNegative Mining에 의해,\n","            # 물체 발견 DBox의 수 num_pos의 3배(self.negpos_ratio 배)로 한다\n","            # 만에 하나, DBox의 수를 초과한 경우에는 DBox의 수를 상한으로 한다\n","            num_neg = torch.clamp(num_pos*self.negpos_ratio, max=num_dbox)\n","\n","            # idx_rank는 각 DBox의 손실의 크기가 위에서 부터 몇 번째인지가 저장되어 있다\n","            # 배경 DBox의 수 num_neg보다 순위가 낮은(손실이 큰) DBox를 취하는 마스크를 작성\n","            # torch.Size([num_batch, 8732])\n","            neg_mask = idx_rank < (num_neg).expand_as(idx_rank)\n","\n","            # -----------------\n","            # (종료) 이제부터 Negative DBox 중에서, Hard Negative Mining로 추출할 것을 구하는 마스크를 작성합니다\n","            # -----------------\n","\n","            # 마스크의 모양을 성형하여 conf_data에 맞춘다\n","            # pos_idx_mask는 Positive DBox의 conf를 꺼내는 마스크입니다\n","            # neg_idx_mask는 Hard Negative Mining으로 추출한 Negative DBox의 conf를 꺼내는 마스크입니다\n","            # pos_mask: torch.Size([num_batch, 8732])→pos_idx_mask: torch.Size([num_batch, 8732, 21])\n","            pos_idx_mask = pos_mask.unsqueeze(2).expand_as(conf_data)\n","            neg_idx_mask = neg_mask.unsqueeze(2).expand_as(conf_data)\n","\n","            # conf_data에서 pos와 neg만 꺼내서 conf_hnm으로 한다. 형태는 torch.Size([num_pos+num_neg, 21])\n","            conf_hnm = conf_data[(pos_idx_mask+neg_idx_mask).gt(0)\n","                                ].view(-1, num_classes)\n","            # (주석) gt는 greater than(>)의 약칭. mask가 1인 index를 꺼낸다\n","            # pos_idx_mask+neg_idx_mask는 덧셈이지만, index로 mask를 정리할 뿐이다\n","            # 즉, pos이든 neg이든, 마스크가 1인 것을 더해 하나의 리스트로 만들어, 이를 gt로 취득\n","\n","            # 마찬가지로 지도 데이터인 conf_t_label에서 pos와 neg만 꺼내어 conf_t_label_hnm으로\n","            # torch.Size([pos+neg]) 형태가 된다\n","            conf_t_label_hnm = conf_t_label[(pos_mask+neg_mask).gt(0)]\n","\n","            # confidence의 손실함수를 계산(요소의 합계=sum을 구한다)\n","            loss_c = F.cross_entropy(conf_hnm, conf_t_label_hnm, reduction='sum')\n","\n","            # 물체를 발견한 BBox의 수 N(전체 미니 배치의 합계)으로 손실을 나눔\n","            N = num_pos.sum()\n","            loss_l /= N\n","            loss_c /= N\n","\n","            return loss_l, loss_c"],"metadata":{"id":"KOHwfzE9O5JP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Scratch Notes"],"metadata":{"id":"eqtixndfS97g"}},{"cell_type":"markdown","source":["## torch.Tensor, torch.tensor"],"metadata":{"id":"HnuOQxGCTAAS"}},{"cell_type":"code","source":["torch.Tensor(2, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CVvuMQqdTCdH","executionInfo":{"status":"ok","timestamp":1658231471840,"user_tz":-540,"elapsed":2,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"5c440e02-6cb0-41ae-b755-ab34fdf2d311"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1.6116e-35, 0.0000e+00, 4.4842e-44],\n","        [0.0000e+00,        nan, 1.3873e-43]])"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# torch.tensor(2, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":179},"id":"Icy7fqUPTDo-","executionInfo":{"status":"error","timestamp":1658231477040,"user_tz":-540,"elapsed":7,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"93531c95-0581-488c-e34a-2ae71d1b79d5"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-348b4305455b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: tensor() takes 1 positional argument but 2 were given"]}]},{"cell_type":"code","source":["torch.tensor(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4YOsYSHjTItp","executionInfo":{"status":"ok","timestamp":1658231497253,"user_tz":-540,"elapsed":3,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"3bdf2f41-1f3d-4727-cb57-19c05de5e4cb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["torch.tensor([2, 3]).dim()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WpUV14pgTE3d","executionInfo":{"status":"ok","timestamp":1658231767503,"user_tz":-540,"elapsed":6,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"6813255f-c501-4169-84cd-a6d754bf4f96"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["torch.tensor([[2, 3]]).dim()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7KWdJdU4ULzI","executionInfo":{"status":"ok","timestamp":1658231777074,"user_tz":-540,"elapsed":4,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"9e01c64c-bfb4-45af-808e-bae2ace8be33"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":[""],"metadata":{"id":"gAqByN4aUOG9"},"execution_count":null,"outputs":[]}]}