{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2-8_SSD_inference_appendix.ipynb","provenance":[],"mount_file_id":"15jVxzb0zgQX4vNbWGzcBoe7Y5szeHruW","authorship_tag":"ABX9TyPDcz30Eqa1DfB2Sp0jqwXx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["%load_ext autoreload\n","%autoreload 2"],"metadata":{"id":"ZGdjkGIkJ-yr","executionInfo":{"status":"ok","timestamp":1658296230607,"user_tz":-540,"elapsed":357,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/data_science_project/pytorch_tutorial/2_object_detection"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TQawXj3kKehx","executionInfo":{"status":"ok","timestamp":1658296373186,"user_tz":-540,"elapsed":480,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"c50dba28-f517-4cf3-ee64-721520261b5d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/data_science_project/pytorch_tutorial/2_object_detection\n"]}]},{"cell_type":"code","execution_count":1,"metadata":{"id":"04-fkRJiJ4Mo","executionInfo":{"status":"ok","timestamp":1658296211325,"user_tz":-540,"elapsed":3327,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"outputs":[],"source":["import cv2  # OpenCV 라이브러리\n","import matplotlib.pyplot as plt \n","import numpy as np\n","import torch\n","\n","%matplotlib inline"]},{"cell_type":"code","source":["def ssd_predict(img_index, img_list, dataset, net=None, dataconfidence_level=0.5):\n","    \"\"\"\n","    SSD로 예측하는 함수\n","\n","    Parameters\n","    ----------\n","    img_index:  int\n","        데이터 세트 내의 예측 대상 화상의 인덱스\n","    img_list: list\n","        화상의 파일 경로 리스트\n","    dataset: PyTorch의 Dataset\n","        화상의 Dataset\n","    net: PyTorch의 Network\n","        학습시킨 SSD 네트워크\n","    dataconfidence_level: float\n","        예측에서 발견했다고 여기는 신뢰도의 임계치\n","\n","    Returns\n","    -------\n","    rgb_img, true_bbox, true_label_index, predict_bbox, pre_dict_label_index, scores\n","    \"\"\"\n","\n","    # rgb의 화상 데이터를 취득\n","    image_file_path = img_list[img_index]\n","    img = cv2.imread(image_file_path)  # [높이][폭][색BGR]\n","    height, width, channels = img.shape  # 화상 크기 취득\n","    rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","    # 정답 BBox를 취득\n","    im, gt = dataset.__getitem__(img_index)\n","    true_bbox = gt[:, 0:4] * [width, height, width, height]\n","    true_label_index = gt[:, 4].astype(int)\n","\n","    # SSD로 예측\n","    net.eval()  # 네트워크를 추론 모드로\n","    x = im.unsqueeze(0)  # 미니 배치화: torch.Size([1, 3, 300, 300])\n","    detections = net(x)\n","    # detections의 형은, torch.Size([1, 21, 200, 5])  ※200은 top_k의 값\n","\n","    # confidence_level이 기준 이상인 것을 꺼낸다\n","    predict_bbox = []\n","    pre_dict_label_index = []\n","    scores = []\n","    detections = detections.cpu().detach().numpy()\n","\n","    # 조건 이상의 값을 추출\n","    find_index = np.where(detections[:, 0:, :, 0] >= dataconfidence_level)\n","    detections = detections[find_index]\n","    for i in range(len(find_index[1])):  # 추출한 물체수만큼 루프를 돈다\n","        if (find_index[1][i]) > 0:  # 배경 클래스가 아닌 것\n","            sc = detections[i][0]  # 신뢰도\n","            bbox = detections[i][1:] * [width, height, width, height]\n","            lable_ind = find_index[1][i]-1  # find_index는 미니 배치 수, 클래스, top의 tuple\n","            # (주석)\n","            # 배경 클래스는 0이므로 1을 뺀다\n","\n","            # 반환값 리스트에 추가\n","            predict_bbox.append(bbox)\n","            pre_dict_label_index.append(lable_ind)\n","            scores.append(sc)\n","\n","    return rgb_img, true_bbox, true_label_index, predict_bbox, pre_dict_label_index, scores\n"],"metadata":{"id":"i_SageYhJ-Sy","executionInfo":{"status":"ok","timestamp":1658296245089,"user_tz":-540,"elapsed":3,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def vis_bbox(rgb_img, bbox, label_index, scores, label_names):\n","    \"\"\"\n","    물체 감지의 예측 결과를 화상으로 표시하는 함수.\n","\n","    Parameters\n","    ----------\n","    rgb_img:rgb의 화상\n","        대상 화상 데이터\n","    bbox: list\n","        물체의 BBox 리스트\n","    label_index: list\n","        물체의 라벨 인덱스\n","    scores: list\n","        물체의 신뢰도\n","    label_names: list\n","        라벨명의 배열\n","\n","    Returns\n","    -------\n","    없음. rgb_img에 물체 검출 결과가 더해진 화상이 표시된다.\n","    \"\"\"\n","\n","    # 테두리 색상 설정\n","    num_classes = len(label_names)  # 클래스 수(배경 제외)\n","    colors = plt.cm.hsv(np.linspace(0, 1, num_classes)).tolist()\n","\n","    # 화상 표시\n","    plt.figure(figsize=(10, 10))\n","    plt.imshow(rgb_img)\n","    currentAxis = plt.gca()\n","\n","    # BBox만큼 루프\n","    for i, bb in enumerate(bbox):\n","\n","        # 라벨명\n","        label_name = label_names[label_index[i]]\n","        color = colors[label_index[i]]  # 클래스마다 다른 색깔의 테두리를 부여\n","\n","        # 테두리에 붙이는 라벨 (예: person: 0.72)\n","        if scores is not None:\n","            sc = scores[i]\n","            display_txt = '%s: %.2f' % (label_name, sc)\n","        else:\n","            display_txt = '%s: ans' % (label_name)\n","\n","        # 테두리의 좌표\n","        xy = (bb[0], bb[1])\n","        width = bb[2] - bb[0]\n","        height = bb[3] - bb[1]\n","\n","        # 직사각형 그리기\n","        currentAxis.add_patch(plt.Rectangle(\n","            xy, width, height, fill=False, edgecolor=color, linewidth=2))\n","\n","        # 직사각형의 테두리의 좌측 상단에 라벨을 그린다\n","        currentAxis.text(xy[0], xy[1], display_txt, bbox={\n","                         'facecolor': color, 'alpha': 0.5})\n"],"metadata":{"id":"2B80d_ANKJbj","executionInfo":{"status":"ok","timestamp":1658296253194,"user_tz":-540,"elapsed":361,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class SSDPredictShow():\n","    \"\"\"SSD의 예측과 화상의 표시를 한 번에 수행하는 클래스\"\"\"\n","\n","    def __init__(self, img_list, dataset,  eval_categories, net=None, dataconfidence_level=0.6):\n","        self.img_list = img_list\n","        self.dataset = dataset\n","        self.net = net\n","        self.dataconfidence_level = dataconfidence_level\n","        self.eval_categories = eval_categories\n","\n","    def show(self, img_index, predict_or_ans):\n","        \"\"\"\n","        물체 감지의 예측 결과를 표시하는 함수.\n","\n","        Parameters\n","        ----------\n","        img_index:  int\n","            데이터 세트 내의 예측 대상 화상의 인덱스.\n","        predict_or_ans: text\n","            'precit', 'ans'에서, BBox의 예측과 정답 중 어느 것을 표시할지 지정\n","\n","        Returns\n","        -------\n","        없음. rgb_img에 물체 검출 결과가 더해진 화상이 표시된다.\n","        \"\"\"\n","        rgb_img, true_bbox, true_label_index, predict_bbox, pre_dict_label_index, scores = ssd_predict(img_index, self.img_list,\n","                                                                 self.dataset,\n","                                                                 self.net,\n","                                                                 self.dataconfidence_level)\n","\n","        if predict_or_ans == \"predict\":\n","            vis_bbox(rgb_img, bbox=predict_bbox, label_index=pre_dict_label_index,\n","                     scores=scores, label_names=self.eval_categories)\n","\n","        elif predict_or_ans == \"ans\":\n","            vis_bbox(rgb_img, bbox=true_bbox, label_index=true_label_index,\n","                     scores=None, label_names=self.eval_categories)\n"],"metadata":{"id":"AEnFSPyUKLWb","executionInfo":{"status":"ok","timestamp":1658296259729,"user_tz":-540,"elapsed":397,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from utils.ssd_model import make_datapath_list, VOCDataset, DataTransform, Anno_xml2list, od_collate_fn\n","\n","\n","# 파일 경로 리스트를 취득\n","rootpath = \"./data/VOCdevkit/VOC2012/\"\n","train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(\n","    rootpath)\n","\n","# Dataset을 작성\n","voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n","               'bottle', 'bus', 'car', 'cat', 'chair',\n","               'cow', 'diningtable', 'dog', 'horse',\n","               'motorbike', 'person', 'pottedplant',\n","               'sheep', 'sofa', 'train', 'tvmonitor']\n","color_mean = (104, 117, 123)  # (BGR)의 색 평균값\n","input_size = 300  # 화상의 input 크기를 300×300로 한다\n","\n","train_dataset = VOCDataset(train_img_list, train_anno_list, phase=\"val\", transform=DataTransform(\n","    input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n","\n","val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\", transform=DataTransform(\n","    input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n","\n"],"metadata":{"id":"JwRyslEBKM-U","executionInfo":{"status":"ok","timestamp":1658296380343,"user_tz":-540,"elapsed":3932,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["from utils.ssd_model import SSD\n","\n","# SSD300の設定\n","ssd_cfg = {\n","    'num_classes': 21,  # 배경 클래스를 포함한 총 클래스 수\n","    'input_size': 300,  # 화상의 입력 크기\n","    'bbox_aspect_num': [4, 6, 6, 6, 4, 4],  # 출력할 Box 화면비의 종류\n","    'feature_maps': [38, 19, 10, 5, 3, 1],  # 각 source의 화상 크기\n","    'steps': [8, 16, 32, 64, 100, 300],  # DBOX의 크기를 정한다\n","    'min_sizes': [30, 60, 111, 162, 213, 264],  # DBOX의 크기를 정한다\n","    'max_sizes': [60, 111, 162, 213, 264, 315],  # DBOX의 크기를 정한다\n","    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n","}\n","\n","# SSD 네트워크 모델\n","net = SSD(phase=\"inference\", cfg=ssd_cfg)\n","net.eval()\n","\n","# SSD의 학습된 가중치를 설정\n","# net_weights = torch.load('./weights/ssd300_50.pth',\n","#                          map_location={'cuda:0': 'cpu'})\n","\n","net_weights = torch.load('./weights/ssd300_mAP_77.43_v2.pth',\n","                        map_location={'cuda:0': 'cpu'})\n","\n","net.load_state_dict(net_weights)\n","\n","# GPU를 사용할 수 있는지 확인\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"사용 중인 장치:\", device)\n","\n","print('네트워크 설정 완료: 학습된 가중치를 로드했습니다')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kR4_fRTyK0zH","executionInfo":{"status":"ok","timestamp":1658296642953,"user_tz":-540,"elapsed":1169,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"d44312d6-6f9b-4299-f28b-5e43ed9a8166"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["사용 중인 장치: cpu\n","네트워크 설정 완료: 학습된 가중치를 로드했습니다\n"]}]},{"cell_type":"code","source":["# 결과 그리기\n","ssd = SSDPredictShow(img_list=train_img_list, dataset=train_dataset, eval_categories=voc_classes,\n","                     net=net, dataconfidence_level=0.6)\n","img_index = 0\n","ssd.show(img_index, \"predict\")\n","ssd.show(img_index, \"ans\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1w9TrjqfPSmZLwJ-cbtC-hyxqe-ZoUJ4P"},"id":"TZWc6wfHKdMx","executionInfo":{"status":"ok","timestamp":1658296641796,"user_tz":-540,"elapsed":217216,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"2abffa3c-489c-4517-caa3-9f075dd91899"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[""],"metadata":{"id":"x8HhXTq5KuLB"},"execution_count":null,"outputs":[]}]}